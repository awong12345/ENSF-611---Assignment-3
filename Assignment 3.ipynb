{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92778525",
   "metadata": {},
   "source": [
    "# Assignment 3: Non-Linear Models and Validation Metrics (37 total marks)\n",
    "### Due: October 24 at 11:59pm\n",
    "\n",
    "### Name: Alton Wong"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce31b39a",
   "metadata": {},
   "source": [
    "### In this assignment, you will need to write code that uses non-linear models to perform classification and regression tasks. You will also be asked to describe the process by which you came up with the code. More details can be found below. Please cite any websites or AI tools that you used to help you with this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf275ca7",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b67a661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yellowbrick\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee2d2c3",
   "metadata": {},
   "source": [
    "## Part 1: Regression (14.5 marks)\n",
    "\n",
    "For this section, we will be continuing with the concrete example from yellowbrick. You will need to compare these results to the results from the previous assignment. Please use the results from the solution if you were unable to complete Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8219f163",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (0.5 marks)\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library: \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/concrete.html\n",
    "\n",
    "Use the yellowbrick function `load_concrete()` to load the concrete dataset into the feature matrix `X` and target vector `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2af8bd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Import concrete dataset from yellowbrick library\n",
    "from yellowbrick.datasets import load_concrete\n",
    "X, y = yellowbrick.datasets.loaders.load_concrete(data_home = None, return_dataset = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fea4cc",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (0 marks)\n",
    "\n",
    "Data processing was completed in the previous assignment. No need to repeat here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a245d00",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import the Decision Tree, Random Forest and Gradient Boosting Machines regression models from sklearn\n",
    "2. Instantiate the three models with `max_depth = 5`. Are there any other parameters that you will need to set?\n",
    "3. Implement each machine learning model with `X` and `y`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f994e31",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model\n",
    "\n",
    "Calculate the average training and validation accuracy using mean squared error with cross-validation. To do this, you will need to set `scoring='neg_mean_squared_error'` in your `cross_validate` function and negate the results (multiply by -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc3f7a8",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (4 marks)\n",
    "\n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy, and index: DT, RF and GB\n",
    "2. Add the accuracy results to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdc93a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Training accuracy  Validation accuracy\n",
      "Decision Tree                      47.279761            73.447331\n",
      "Random Forest                      29.577455            45.059351\n",
      "GradientBoostingRegressor           3.379440            22.783221\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state = 0)\n",
    "tree = DecisionTreeRegressor(max_depth= 5, random_state= 0).fit(X_train, y_train)\n",
    "forest = RandomForestRegressor(max_depth= 5, random_state= 0).fit(X_train, y_train)\n",
    "gradient = GradientBoostingRegressor(max_depth= 5, random_state= 0).fit(X_train, y_train)\n",
    "\n",
    "models = {'Decision Tree': tree, 'Random Forest': forest, 'GradientBoostingRegressor': gradient}\n",
    "results = {\"Training accuracy\":[],\"Validation accuracy\":[]}\n",
    "for name, model in models.items():\n",
    "    scores = cross_validate(model, X_train, y_train, cv= 5, scoring= 'neg_mean_squared_error',return_train_score= True)\n",
    "    train_mse = (-1)*np.mean(scores['train_score'])\n",
    "    test_mse = (-1)*np.mean(scores['test_score'])\n",
    "    results[\"Training accuracy\"].append(train_mse)\n",
    "    results[\"Validation accuracy\"].append(test_mse)\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "results_df.index = [\"Decision Tree\", \"Random Forest\", \"GradientBoostingRegressor\"]\n",
    "print(results_df)\n",
    "   \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31715a9d",
   "metadata": {},
   "source": [
    "Repeat the step above to print the R2 score instead of the mean-squared error. For this case, you can use `scoring='r2'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83539f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Training accuracy  Validation accuracy\n",
      "Decision Tree                       0.834465             0.738697\n",
      "Random Forest                       0.896557             0.840927\n",
      "GradientBoostingRegressor           0.988171             0.919471\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "models = {'Decision Tree': tree, 'Random Forest': forest, 'GradientBoostingRegressor': gradient}\n",
    "results = {\"Training accuracy\":[], \"Validation accuracy\":[]}\n",
    "for name, model in models.items():\n",
    "    scores = cross_validate(model, X_train, y_train, cv= 5, scoring= 'r2',return_train_score= True)\n",
    "    train_r2 = np.mean(scores['train_score'])\n",
    "    test_r2 = np.mean(scores['test_score'])\n",
    "    results[\"Training accuracy\"].append(train_r2)\n",
    "    results[\"Validation accuracy\"].append(test_r2)\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "results_df.index = [\"Decision Tree\", \"Random Forest\", \"GradientBoostingRegressor\"]\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5257a98",
   "metadata": {},
   "source": [
    "### Questions (6 marks)\n",
    "1. How do these results compare to the results using a linear model in the previous assignment? Use values.\n",
    "1. Out of the models you tested, which model would you select for this dataset and why?\n",
    "1. If you wanted to increase the accuracy of the tree-based models, what would you do? Provide two suggestions.\n",
    "\n",
    "*ANSWER HERE*\n",
    "\n",
    "From assignment 2, the scores calculated from linear regression are:      \n",
    "\n",
    "Training accuracy  Validation accuracy\n",
    "\n",
    "MSE             111.358439               95.904136\n",
    "\n",
    "R2                0.610823                 0.623414\n",
    "\n",
    "Compaing the results above to the results achieved from decision tree regression, random forest regression, and gradient boostingregressor. The tree-based regression models used yielded better results compared to the linear regression used in A2. The MSE scores are lower, and the R2 scores are higher. \n",
    "\n",
    "The gradient boosting regressor would be the best choice as it yielded the best results (lowest MSE and highest R2 score).\n",
    "\n",
    "One way to increase the accuracy would be to play around with the maximum depth of the tree, but that requires some fine tuning as you don't want to overfit or underfit the model. Another way to increase the accuracy would be to increase the n_estimators in both the random forest and gradient boosting regressor.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b238f4",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93097bfe",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE*\n",
    "\n",
    "For part 1 of the assignment I referred back to the python examples shown in class as well as in the lab.  I also referred to the sklearn website for the decision tree regressors, and all the parameters involved. \n",
    "I did not have to use generative AI for this portion of the assignment.\n",
    "The biggest challenge was figuring out how to use cross_validate and which sets of data to use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c6de86",
   "metadata": {},
   "source": [
    "## Part 2: Classification (17.5 marks)\n",
    "\n",
    "You have been asked to develop code that can help the user classify different wine samples. Following the machine learning workflow described in class, write the relevant code in each of the steps below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9d33a8",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (2 marks)\n",
    "\n",
    "The data used for this task can be downloaded from UCI: https://archive.ics.uci.edu/dataset/109/wine\n",
    "\n",
    "Use the pandas library to load the dataset. You must define the column headers if they are not included in the dataset \n",
    "\n",
    "You will need to split the dataset into feature matrix `X` and target vector `y`. Which column represents the target vector?\n",
    "\n",
    "Print the size and type of `X` and `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33583c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of X is: 2314, and type of X is: <class 'pandas.core.frame.DataFrame'>\n",
      "Size of y is: 178, and type of y is: <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Import wine dataset\n",
    "def load_wine():\n",
    "    'Load wine data. It will be downloaded from https://archive.ics.uci.edu/dataset/109/wine.'\n",
    "    \n",
    "    import os\n",
    "    import requests\n",
    "\n",
    "    file_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data'\n",
    "    file_name = file_url.split('/')[-1]\n",
    "\n",
    "    if not os.path.isfile(file_name):\n",
    "        print('Downloading from{}'.format(file_url))\n",
    "        r = requests.get(file_url)\n",
    "        with open(file_name,'wb') as output_file:\n",
    "            output_file.write(r.content)\n",
    "\n",
    "    data = pd.read_csv(file_name, na_values = '?', names=['class', 'Alchol', 'Malicacid', 'Ash', 'Alcalinity_of_ash', 'Magnesium','Total_phenols','Flavanoids','Nonflavanoid_phenols','Proanthocyanins','Color_intensity','Hue','0D280_0D315_of_diluted_wines','Proline'])\n",
    "    \n",
    "\n",
    "    return data\n",
    "\n",
    "data = load_wine()\n",
    "X = data.drop(\"class\", axis = 1)\n",
    "y = data[\"class\"]\n",
    "print(f\"Size of X is: {X.size}, and type of X is: {type(X)}\")\n",
    "print(f\"Size of y is: {y.size}, and type of y is: {type(y)}\")\n",
    "# print(X.shape)\n",
    "# print(y.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156db208",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (1.5 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28af110",
   "metadata": {},
   "source": [
    "Print the first five rows of the dataset to inspect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea266921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>Alchol</th>\n",
       "      <th>Malicacid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity_of_ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total_phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid_phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color_intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>0D280_0D315_of_diluted_wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  Alchol  Malicacid   Ash  Alcalinity_of_ash  Magnesium  \\\n",
       "0      1   14.23       1.71  2.43               15.6        127   \n",
       "1      1   13.20       1.78  2.14               11.2        100   \n",
       "2      1   13.16       2.36  2.67               18.6        101   \n",
       "3      1   14.37       1.95  2.50               16.8        113   \n",
       "4      1   13.24       2.59  2.87               21.0        118   \n",
       "\n",
       "   Total_phenols  Flavanoids  Nonflavanoid_phenols  Proanthocyanins  \\\n",
       "0           2.80        3.06                  0.28             2.29   \n",
       "1           2.65        2.76                  0.26             1.28   \n",
       "2           2.80        3.24                  0.30             2.81   \n",
       "3           3.85        3.49                  0.24             2.18   \n",
       "4           2.80        2.69                  0.39             1.82   \n",
       "\n",
       "   Color_intensity   Hue  0D280_0D315_of_diluted_wines  Proline  \n",
       "0             5.64  1.04                          3.92     1065  \n",
       "1             4.38  1.05                          3.40     1050  \n",
       "2             5.68  1.03                          3.17     1185  \n",
       "3             7.80  0.86                          3.45     1480  \n",
       "4             4.32  1.04                          2.93      735  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834fc8fe",
   "metadata": {},
   "source": [
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97c6e9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 missing values in the dataset\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "missing_value = X.isnull().sum().sum()+y.isnull().sum()\n",
    "print(f\"There are {missing_value} missing values in the dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070956af",
   "metadata": {},
   "source": [
    "How many samples do we have of each type of wine?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b37a6fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are:\n",
      " class\n",
      "2    71\n",
      "1    59\n",
      "3    48\n",
      "Name: count, dtype: int64 \n",
      "types of wine\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "wine_count = y.value_counts()\n",
    "print(f\"There are:\\n {wine_count} \\ntypes of wine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e6c46f",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import `SVC` and `DecisionTreeClassifier` from sklearn\n",
    "2. Instantiate models as `SVC()` and `DecisionTreeClassifier(max_depth = 3)`\n",
    "3. Implement the machine learning model with `X` and `y`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0870b0d2",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model \n",
    "\n",
    "Calculate the average training and validation accuracy using `cross_validate` for the two different models listed in Step 3. For this case, use `scoring='accuracy'`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0bbd83",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (4 marks)\n",
    "\n",
    "#### Step 5.1: Compare Models\n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy\n",
    "2. Add the data size, training and validation accuracy for each dataset to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be4b5c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Training accuracy  Validation accuracy\n",
      "SVC                              0.680427             0.676638\n",
      "DecisionTreeClassifier           0.994357             0.894017\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state= 0)\n",
    "\n",
    "svc = SVC(random_state= 0).fit(X_train, y_train)\n",
    "tree = DecisionTreeClassifier(max_depth= 3, random_state= 0).fit(X_train, y_train)\n",
    "\n",
    "model = {\"SVC\": svc, \"DecisionTreeClassifier\": tree}\n",
    "results = {\"Training accuracy\":[], \"Validation accuracy\":[]}\n",
    "\n",
    "\n",
    "for name, model in model.items():\n",
    "    scores = cross_validate(model, X_train, y_train, cv= 5, scoring= 'accuracy',return_train_score= True)\n",
    "    cv_train = np.mean(scores[\"train_score\"])\n",
    "    cv_test = np.mean(scores[\"test_score\"])\n",
    "    results[\"Training accuracy\"].append(cv_train)\n",
    "    results[\"Validation accuracy\"].append(cv_test)\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "results_df.index = ['SVC', 'DecisionTreeClassifier']\n",
    "print(results_df)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e17878",
   "metadata": {},
   "source": [
    "#### Step 5.2: Visualize Classification Errors\n",
    "Which method gave the highest accuracy? Use this method to print the confusion matrix and classification report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44b091a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Implement best model\n",
    "#Based off results_df, assume DecisionTreeClassifier is the best\n",
    "model1 = tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09d21b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(170.97222222222223, 0.5, 'True value')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TO DO: Print confusion matrix using a heatmap\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "mat = confusion_matrix(y_val, model1.predict(X_val))\n",
    "\n",
    "sns.heatmap(mat, square=True, annot=True, cbar=False)\n",
    "plt.xlabel('Predicted value')\n",
    "plt.ylabel('True value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ef95947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.88      0.93        16\n",
      "           2       0.91      0.95      0.93        21\n",
      "           3       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.93        45\n",
      "   macro avg       0.93      0.94      0.93        45\n",
      "weighted avg       0.94      0.93      0.93        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Print classification report\n",
    "print(classification_report(y_val, model1.predict(X_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf319621",
   "metadata": {},
   "source": [
    "### Questions (6 marks)\n",
    "1. How do the training and validation accuracy change depending on the method used? Explain with values.\n",
    "1. What are two reasons why the support vector machines model did not work as well as the tree-based model?\n",
    "1. How many samples were incorrectly classified in step 5.2? \n",
    "1. In this case, is maximizing precision or recall more important? Why?\n",
    "\n",
    "*YOUR ANSWERS HERE*\n",
    "\n",
    "The training and validation accuracy differ a lot between the two methods used. The decision tree classifier has much higher accuracy scores for both the training(0.994357) and testing(0.894017) set. Whereas the SVC method yielded values of 0.680427 for training and 0.676638 for testing. \n",
    "\n",
    "Two reasons why the SVM did not work is well is because we used default C and gamma values to fit our model.\n",
    "\n",
    "The model incorrectly classified 3 samples (the sum of values outside the diagonal in the heatmap)\n",
    "\n",
    "Since we are classifying wine samples, I would say that precision may be more important as we want to be more precise with properly classifying the wine. However, with precision and recall, they are trade-offs. So if we prioritize one, then the other will get worse.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664ff8ae",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e837da",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE*\n",
    "\n",
    "For part 2 of the assignment I also followed along with the Python notebooks covered in class as well as referred to the lab notes. \n",
    "I completed this assignment in the order it was provided. Following steps 1 and working my way down through the assignment.\n",
    "\n",
    "I did have to use ChatGPT : \"Can you explain which is better when doing machine learning modelling. Precision or recall? and why?\"\n",
    "I also used ChatGPT to help de-bug my code, as I was having trouble uploading the dataset using the method shown in class. ChatGPT was able to give me the url to the Wine dataset. \n",
    "\n",
    "Part 2 of the assignment was relatively straightforward. Following along with the examples done in class and class notes helped a lot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd7358d",
   "metadata": {},
   "source": [
    "## Part 3: Observations/Interpretation (3 marks)\n",
    "\n",
    "Describe any pattern you see in the results. Relate your findings to what we discussed during lectures. Include data to justify your findings.\n",
    "\n",
    "\n",
    "*ADD YOUR FINDINGS HERE*\n",
    "\n",
    "Which model to select comes down to what we are trying to achieve from our data. And also, the type of data provided makes a big difference on what type of model we should select.  Also, knowing how to modify hyper parameters of the model is very difficult and involves some trial and error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd97b6ac",
   "metadata": {},
   "source": [
    "## Part 4: Reflection (2 marks)\n",
    "Include a sentence or two about:\n",
    "- what you liked or disliked,\n",
    "- found interesting, confusing, challangeing, motivating\n",
    "while working on this assignment.\n",
    "\n",
    "\n",
    "*ADD YOUR THOUGHTS HERE*\n",
    "\n",
    "Like the previous assignment, I like that these assignments are building on things that we learn in class, and not just leaving us googling how to do the whole assignment.  It helps to reinforce the learnings taught in lecture.\n",
    "\n",
    "It is interesting to see the comparisons of accuracy scores depending on which model is used, and diving deeper into why one model works better than the other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa21e53b",
   "metadata": {},
   "source": [
    "## Part 5: Bonus Question (3 marks)\n",
    "\n",
    "Repeat Part 2 and compare the support vector machines model used to `LinearSVC(max_iter=5000)`. Does using `LinearSVC` improve the results? Why or why not?\n",
    "\n",
    "Is `LinearSVC` a good fit for this dataset? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "30fea72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/AltonWong/anaconda3/envs/ensf-ml2/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/AltonWong/anaconda3/envs/ensf-ml2/lib/python3.11/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/AltonWong/anaconda3/envs/ensf-ml2/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/AltonWong/anaconda3/envs/ensf-ml2/lib/python3.11/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/AltonWong/anaconda3/envs/ensf-ml2/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/AltonWong/anaconda3/envs/ensf-ml2/lib/python3.11/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/AltonWong/anaconda3/envs/ensf-ml2/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/AltonWong/anaconda3/envs/ensf-ml2/lib/python3.11/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/AltonWong/anaconda3/envs/ensf-ml2/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/AltonWong/anaconda3/envs/ensf-ml2/lib/python3.11/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/AltonWong/anaconda3/envs/ensf-ml2/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/AltonWong/anaconda3/envs/ensf-ml2/lib/python3.11/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "linear_svc = LinearSVC(max_iter=5000, random_state=0).fit(X_train, y_train)\n",
    "score_lsvc = cross_validate(linear_svc, X_train, y_train, cv=5, scoring= 'accuracy', return_train_score=True)\n",
    "lsvc_train = np.mean(scores[\"train_score\"])\n",
    "lsvc_test = np.mean(scores[\"test_score\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "241c3b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC scores:\n",
      "Training Accuracy: 0.9943572562158348\n",
      "Testing Accuracy: 0.8940170940170941\n"
     ]
    }
   ],
   "source": [
    "print(f\"LinearSVC scores:\\nTraining Accuracy: {lsvc_train}\\nTesting Accuracy: {lsvc_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabc68a4",
   "metadata": {},
   "source": [
    "*ANSWER HERE*\n",
    "\n",
    "Using LinearSVC does improve the results. Both training and testing accuracy went up substantially vs SVC. \n",
    "\n",
    "LinearSVC would be a good choice for this model as the scores are so high."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
